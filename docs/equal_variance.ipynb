{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import poisson\n",
    "import statsmodels.formula.api as sm\n",
    "import warnings\n",
    "from os import path as path\n",
    "import math\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def LLR2p(LLR):\n",
    "    LR = np.exp(LLR)\n",
    "    return (LR)/(1+LR)\n",
    "\n",
    "def LLR2pcorrect(LLR):\n",
    "    return (LLR2p(np.abs(LLR)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discrimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiscriminationModel:\n",
    "    def __init__(self, mu, sigma, perceptual_noise):\n",
    "        \n",
    "        self.df = pd.DataFrame()\n",
    "        self.mu = mu\n",
    "        self.sigma = sigma\n",
    "        self.perceptual_noise = perceptual_noise\n",
    "        \n",
    "        self.signal_dist = stats.norm(self.mu[1],np.sqrt(self.sigma[1]**+self.perceptual_noise**2));\n",
    "        self.noise_dist = stats.norm(self.mu[0],np.sqrt(self.sigma[0]**+self.perceptual_noise**2));\n",
    "\n",
    "    def runModel(self, num_trials, num_timepoints):\n",
    "        \n",
    "        self.num_trials = num_trials;\n",
    "        self.num_timepoints = num_timepoints;\n",
    "        \n",
    "        self.df['trial_id'] = range(num_trials);\n",
    "        \n",
    "        # first, decide which is the true direction in each trial (p=0.5)\n",
    "        self.df['bright_side'] = [1 if flip else 0 \n",
    "                                for flip in np.random.binomial(1,0.5,num_trials)] \n",
    "        \n",
    "        # duplicate each row num_timepoints times\n",
    "        self.df = self.df.loc[self.df.index.repeat(num_timepoints)].reset_index(drop=True)\n",
    "\n",
    "        self.df['timepoint'] = list(range(1,num_timepoints+1))*num_trials;\n",
    "        \n",
    "        # duplicate each row twice (for the two evidence channels)\n",
    "        self.df = self.df.loc[self.df.index.repeat(2)].reset_index(drop=True)\n",
    "        \n",
    "        self.df['side'] = [1,0] * num_trials*num_timepoints;\n",
    "        \n",
    "        self.getMotionEnergy()\n",
    "        \n",
    "        self.extractLLR()\n",
    "\n",
    "        # I didn't have a better word for this part, which includes processing\n",
    "        # the stimuli, making a decision and rating confidence. \n",
    "        self.behave()\n",
    "        \n",
    "        self.df['correct'] = self.df.apply(lambda row: \n",
    "                                           row.bright_side==row.decision, axis=1)\n",
    "        \n",
    "    def getMotionEnergy(self):\n",
    "        \n",
    "        # sample the motion energy for left and right as a function of the true direction\n",
    "        self.df['evidence'] = self.df.apply(lambda row: \n",
    "                      np.random.normal(self.mu[1],self.sigma[1]) \n",
    "                      if row.side==row.bright_side\n",
    "                      else np.random.normal(self.mu[0],self.sigma[0]),\n",
    "                      axis=1)\n",
    "\n",
    "        # how it appears to subjects\n",
    "        self.df['percept'] = self.df.apply(lambda row: row.evidence +\n",
    "                        np.random.normal(0, self.perceptual_noise), \n",
    "                        axis=1);\n",
    "    \n",
    "    def extractLLR(self):\n",
    "        \n",
    "        # extract the Log Likelihood Ratio (LLR) \n",
    "        #log(p(evidence|signal))-log(p(evidence|noise))\n",
    "        self.df['sample_LLR'] = self.df.apply(lambda row: self.signal_dist.logpdf(row.percept)-\n",
    "                                              self.noise_dist.logpdf(row.percept), axis=1)\n",
    "        \n",
    "    def behave(self):\n",
    "        \n",
    "        exp_LLR = [];\n",
    "        exp_decision = [];\n",
    "        exp_confidence = [];\n",
    "\n",
    "        trials=self.df.trial_id.unique()\n",
    "\n",
    "        for i_trial in range(self.num_trials):\n",
    "            trial_df = self.df[self.df.trial_id==i_trial]\n",
    "            trial_LLR = [0,0];\n",
    "\n",
    "            LLR = 0;\n",
    "            \n",
    "            for i_timepoint in range(2,self.num_timepoints+1):\n",
    "\n",
    "                sample1 = trial_df[(trial_df.timepoint==i_timepoint) & \n",
    "                                   (trial_df.side==1)]['sample_LLR'].values[0];\n",
    "                sample0 = trial_df[(trial_df.timepoint==i_timepoint) & \n",
    "                                   (trial_df.side==0)]['sample_LLR'].values[0];\n",
    "                LLR = LLR+sample1-sample0;\n",
    "\n",
    "                trial_LLR += [LLR,LLR]\n",
    "\n",
    "            trial_decision = [int(LLR>0)]*24\n",
    "            trial_confidence = [LLR2pcorrect(LLR)]*24     \n",
    "\n",
    "            exp_LLR = exp_LLR + trial_LLR;\n",
    "            exp_decision = exp_decision+trial_decision;\n",
    "            exp_confidence = exp_confidence+trial_confidence;\n",
    "\n",
    "        self.df['LLR'] = exp_LLR;\n",
    "        self.df['decision'] = exp_decision;\n",
    "        self.df['confidence'] = exp_confidence;\n",
    "        \n",
    "    def save(self,file_name):\n",
    "        self.df.to_csv(file_name);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '..\\\\simulations\\\\equal_variance\\\\discrimination.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15392/3523555982.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0muv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDiscriminationModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0muv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrunModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m uv.save(path.join(\n\u001b[0m\u001b[0;32m      6\u001b[0m         '..','simulations','equal_variance','discrimination.csv'))\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15392/3692074322.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, file_name)\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 101\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3464\u001b[0m         )\n\u001b[0;32m   3465\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3466\u001b[1;33m         return DataFrameRenderer(formatter).to_csv(\n\u001b[0m\u001b[0;32m   3467\u001b[0m             \u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3468\u001b[0m             \u001b[0mline_terminator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mline_terminator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\formats\\format.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1103\u001b[0m             \u001b[0mformatter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         )\n\u001b[1;32m-> 1105\u001b[1;33m         \u001b[0mcsv_formatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1107\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcreated_buffer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    235\u001b[0m         \"\"\"\n\u001b[0;32m    236\u001b[0m         \u001b[1;31m# apply compression and byte/text conversion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 237\u001b[1;33m         with get_handle(\n\u001b[0m\u001b[0;32m    238\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    700\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '..\\\\simulations\\\\equal_variance\\\\discrimination.csv'"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "uv=DiscriminationModel([0,0.5],[1,1],2)\n",
    "uv.runModel(10000,12)\n",
    "uv.save(path.join(\n",
    "        '..','simulations','equal_variance','discrimination.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DetectionModel:\n",
    "    def __init__(self, mu, sigma, perceptual_noise):\n",
    "        \n",
    "        self.df = pd.DataFrame()\n",
    "        self.mu = mu\n",
    "        self.sigma = sigma\n",
    "        self.perceptual_noise= perceptual_noise;\n",
    "        \n",
    "        self.signal_dist = stats.norm(self.mu[1],np.sqrt(self.sigma[1]**+self.perceptual_noise**2));\n",
    "        self.noise_dist = stats.norm(self.mu[0],np.sqrt(self.sigma[0]**+self.perceptual_noise**2));\n",
    "      \n",
    "    def runModel(self, num_trials, num_timepoints):\n",
    "        \n",
    "        self.num_trials = num_trials;\n",
    "        self.num_timepoints = num_timepoints;\n",
    "        \n",
    "        self.df['trial_id'] = range(num_trials);\n",
    "        \n",
    "        # first, decide which is the true direction in each trial (p=0.5)\n",
    "        self.df['bright_side'] = [1 if flip else 0 \n",
    "                                for flip in np.random.binomial(1,0.5,num_trials)] \n",
    "        \n",
    "        # first, decide which is the true direction in each trial (p=0.5)\n",
    "        self.df['signal'] = [1 if flip else 0 \n",
    "                                for flip in np.random.binomial(1,0.5,num_trials)] \n",
    "        \n",
    "        # duplicate each row num_timepoints times\n",
    "        self.df = self.df.loc[self.df.index.repeat(num_timepoints)].reset_index(drop=True)\n",
    "\n",
    "        self.df['timepoint'] = list(range(1,num_timepoints+1))*num_trials;\n",
    "        \n",
    "        # duplicate each row twice (for the two evidence channels)\n",
    "        self.df = self.df.loc[self.df.index.repeat(2)].reset_index(drop=True)\n",
    "        \n",
    "        self.df['side'] = [1,0] * num_trials*num_timepoints;\n",
    "        \n",
    "        self.getMotionEnergy()\n",
    "        \n",
    "        self.extractLLR()\n",
    "\n",
    "        # I didn't have a better word for this part, which includes processing\n",
    "        # the stimuli, making a decision and rating confidence. \n",
    "        self.behave()\n",
    "        \n",
    "        self.df['correct'] = self.df.apply(lambda row: \n",
    "                                           row.signal==row.decision, axis=1)\n",
    "        \n",
    "    def getMotionEnergy(self):\n",
    "        \n",
    "        # sample the motion energy for left and right as a function of the true direction\n",
    "        self.df['evidence'] = self.df.apply(lambda row: \n",
    "                      np.random.normal(self.mu[1],self.sigma[1]) \n",
    "                      if (row.side==row.bright_side) & (row.signal)==1\n",
    "                      else np.random.normal(self.mu[0],self.sigma[0]),\n",
    "                      axis=1)\n",
    "\n",
    "        # how it appears to subjects\n",
    "        self.df['percept'] = self.df.apply(lambda row: row.evidence +\n",
    "                        np.random.normal(0, self.perceptual_noise), \n",
    "                        axis=1);\n",
    "    \n",
    "    def extractLLR(self):\n",
    "        \n",
    "        self.df['likelihood_signal'] = self.df.apply(lambda row: self.signal_dist.pdf(row.percept), axis=1);\n",
    "        self.df['likelihood_noise'] = self.df.apply(lambda row: self.noise_dist.pdf(row.percept), axis=1)\n",
    "        \n",
    "        # extract the Log Likelihood Ratio (LLR) \n",
    "        #log(p(evidence|signal))-log(p(evidence|noise))\n",
    "        self.df['sample_LLR'] = self.df.apply(lambda row: self.signal_dist.logpdf(row.percept)-\n",
    "                                              self.noise_dist.logpdf(row.percept), axis=1)\n",
    "        \n",
    "    def behave(self):\n",
    "        \n",
    "        exp_LLR = [];\n",
    "        exp_decision = [];\n",
    "        exp_confidence = [];\n",
    "\n",
    "        trials=self.df.trial_id.unique()\n",
    "\n",
    "        for i_trial in range(self.num_trials):\n",
    "            trial_df = self.df[self.df.trial_id==i_trial]\n",
    "            trial_LLR = [0,0];\n",
    "\n",
    "            LLR1 = 0; # likelihood ratio regarding the two side of the signal, conditioned on that there is a signal\n",
    "            LLR_present = 0;\n",
    "            \n",
    "            for i_timepoint in range(2,self.num_timepoints+1):\n",
    "\n",
    "                sample1 = trial_df[(trial_df.timepoint==i_timepoint) & \n",
    "                                   (trial_df.side==1)]['sample_LLR'].values[0];\n",
    "                sample0 = trial_df[(trial_df.timepoint==i_timepoint) & \n",
    "                                   (trial_df.side==0)]['sample_LLR'].values[0];\n",
    "                \n",
    "                psignal1 = trial_df[(trial_df.timepoint==i_timepoint) & \n",
    "                                   (trial_df.side==1)]['likelihood_signal'].values[0];\n",
    "                psignal0 = trial_df[(trial_df.timepoint==i_timepoint) & \n",
    "                                   (trial_df.side==0)]['likelihood_signal'].values[0];\n",
    "                \n",
    "                pnoise1 = trial_df[(trial_df.timepoint==i_timepoint) & \n",
    "                                   (trial_df.side==1)]['likelihood_noise'].values[0];\n",
    "                pnoise0 = trial_df[(trial_df.timepoint==i_timepoint) & \n",
    "                                   (trial_df.side==0)]['likelihood_noise'].values[0];\n",
    "                \n",
    "                p1 = LLR2p(LLR1); # the probability that side==1\n",
    "                \n",
    "                LLR_present = LLR_present + \\\n",
    "                np.log(p1*psignal1*pnoise0 + (1-p1)*pnoise1*psignal0) - \\\n",
    "                np.log(pnoise0*pnoise1)\n",
    "                \n",
    "                LLR1 = LLR1+sample1-sample0;\n",
    "\n",
    "                trial_LLR += [LLR_present,LLR_present]\n",
    "\n",
    "            trial_decision = [int(LLR_present>0)]*24\n",
    "            trial_confidence = [LLR2pcorrect(LLR_present)]*24     \n",
    "\n",
    "            exp_LLR = exp_LLR + trial_LLR;\n",
    "            exp_decision = exp_decision+trial_decision;\n",
    "            exp_confidence = exp_confidence+trial_confidence;\n",
    "\n",
    "        self.df['LLR'] = exp_LLR;\n",
    "        self.df['decision'] = exp_decision;\n",
    "        self.df['confidence'] = exp_confidence;\n",
    "        \n",
    "    def save(self,file_name):\n",
    "        self.df.to_csv(file_name);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "uv_det=DetectionModel([0,0.5],[1,1],2)\n",
    "uv_det.runModel(10000,12)\n",
    "uv_det.save(path.join(\n",
    "        '..','simulations','equal_variance','detection.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7068"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uv.df.correct.mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import poisson\n",
    "import statsmodels.formula.api as sm\n",
    "import warnings\n",
    "from os import path as path\n",
    "import math\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def LLR2p(LLR):\n",
    "    LR = np.exp(LLR)\n",
    "    return (LR)/(1+LR)\n",
    "\n",
    "def LLR2pcorrect(LLR):\n",
    "    return (LLR2p(np.abs(LLR)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discrimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiscriminationModel:\n",
    "    def __init__(self, mu, sigma):\n",
    "        \n",
    "        self.df = pd.DataFrame()\n",
    "        self.mu = mu\n",
    "        self.sigma = sigma\n",
    "        \n",
    "        X = np.arange(0,200,1)\n",
    "        marginal_signal=[0]*len(X)\n",
    "        marginal_noise=[0]*len(X)\n",
    "\n",
    "        for x in X:\n",
    "          conditional = stats.poisson(max(0,x*20)).pmf(X);\n",
    "          prior_noise = stats.norm(self.mu[0],self.sigma[0]).pdf(x)\n",
    "          prior_signal = stats.norm(self.mu[1],self.sigma[1]).pdf(x)\n",
    "          marginal_noise = [p+conditional[i]*prior_noise \n",
    "                              for i,p in enumerate(marginal_noise)];\n",
    "          marginal_signal = [p+conditional[i]*prior_signal \n",
    "                               for i,p in enumerate(marginal_signal)];\n",
    "\n",
    "\n",
    "        self.signal_dist = marginal_signal;\n",
    "\n",
    "        self.noise_dist = marginal_noise;\n",
    "\n",
    "\n",
    "      \n",
    "    def runModel(self, num_trials, num_timepoints):\n",
    "        \n",
    "        self.num_trials = num_trials;\n",
    "        self.num_timepoints = num_timepoints;\n",
    "        \n",
    "        self.df['trial_id'] = range(num_trials);\n",
    "        \n",
    "        # first, decide which is the true direction in each trial (p=0.5)\n",
    "        self.df['bright_side'] = [1 if flip else 0 \n",
    "                                for flip in np.random.binomial(1,0.5,num_trials)] \n",
    "        \n",
    "        # duplicate each row num_timepoints times\n",
    "        self.df = self.df.loc[self.df.index.repeat(num_timepoints)].reset_index(drop=True)\n",
    "\n",
    "        self.df['timepoint'] = list(range(1,num_timepoints+1))*num_trials;\n",
    "        \n",
    "        # duplicate each row twice (for the two evidence channels)\n",
    "        self.df = self.df.loc[self.df.index.repeat(2)].reset_index(drop=True)\n",
    "        \n",
    "        self.df['side'] = [1,0] * num_trials*num_timepoints;\n",
    "        \n",
    "        self.getMotionEnergy()\n",
    "        \n",
    "        self.extractLLR()\n",
    "\n",
    "        # I didn't have a better word for this part, which includes processing\n",
    "        # the stimuli, making a decision and rating confidence. \n",
    "        self.behave()\n",
    "        \n",
    "        self.df['correct'] = self.df.apply(lambda row: \n",
    "                                           row.bright_side==row.decision, axis=1)\n",
    "        \n",
    "    def getMotionEnergy(self):\n",
    "        \n",
    "        # sample the motion energy for left and right as a function of the true direction\n",
    "        self.df['evidence'] = self.df.apply(lambda row: \n",
    "                      np.random.normal(self.mu[1],self.sigma[1]) \n",
    "                      if row.side==row.bright_side\n",
    "                      else np.random.normal(self.mu[0],self.sigma[0]),\n",
    "                      axis=1)\n",
    "\n",
    "        # how it appears to subjects\n",
    "        self.df['percept'] = self.df.apply(lambda row: np.random.poisson(max(0,row.evidence*20)), \n",
    "                        axis=1);\n",
    "    \n",
    "    def extractLLR(self):\n",
    "        \n",
    "        # extract the Log Likelihood Ratio (LLR) \n",
    "        #log(p(evidence|signal))-log(p(evidence|noise))\n",
    "        self.df['sample_LLR'] = self.df.apply(lambda row: np.log(self.signal_dist[int(row.percept)])-\n",
    "                                              np.log(self.noise_dist[int(row.percept)]), axis=1)\n",
    "\n",
    "        \n",
    "    def behave(self):\n",
    "        \n",
    "        exp_LLR = [];\n",
    "        exp_decision = [];\n",
    "        exp_confidence = [];\n",
    "\n",
    "        trials=self.df.trial_id.unique()\n",
    "\n",
    "        for i_trial in range(self.num_trials):\n",
    "            trial_df = self.df[self.df.trial_id==i_trial]\n",
    "            trial_LLR = [0,0];\n",
    "\n",
    "            LLR = 0;\n",
    "            \n",
    "            for i_timepoint in range(2,self.num_timepoints+1):\n",
    "\n",
    "                sample1 = trial_df[(trial_df.timepoint==i_timepoint) & \n",
    "                                   (trial_df.side==1)]['sample_LLR'].values[0];\n",
    "                sample0 = trial_df[(trial_df.timepoint==i_timepoint) & \n",
    "                                   (trial_df.side==0)]['sample_LLR'].values[0];\n",
    "                LLR = LLR+sample1-sample0;\n",
    "\n",
    "                trial_LLR += [LLR,LLR]\n",
    "\n",
    "            trial_decision = [int(LLR>0)]*24\n",
    "            trial_confidence = [LLR2pcorrect(LLR)]*24     \n",
    "\n",
    "            exp_LLR = exp_LLR + trial_LLR;\n",
    "            exp_decision = exp_decision+trial_decision;\n",
    "            exp_confidence = exp_confidence+trial_confidence;\n",
    "\n",
    "        self.df['LLR'] = exp_LLR;\n",
    "        self.df['decision'] = exp_decision;\n",
    "        self.df['confidence'] = exp_confidence;\n",
    "        \n",
    "    def save(self,file_name):\n",
    "        self.df.to_csv(file_name);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "uv=DiscriminationModel([0,0.5],[1,1])\n",
    "uv.runModel(10000,12)\n",
    "uv.save(path.join(\n",
    "        '..','simulations','poisson_noise','discrimination.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8467"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(uv.df.correct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DetectionModel:\n",
    "    def __init__(self, mu, sigma):\n",
    "        \n",
    "        self.df = pd.DataFrame()\n",
    "        self.mu = mu\n",
    "        self.sigma = sigma\n",
    "        \n",
    "        X = np.arange(0,200,1)\n",
    "        marginal_signal=[0]*len(X)\n",
    "        marginal_noise=[0]*len(X)\n",
    "\n",
    "        for x in X:\n",
    "          conditional = stats.poisson(max(0,x*20)).pmf(X);\n",
    "          prior_noise = stats.norm(self.mu[0],self.sigma[0]).pdf(x)\n",
    "          prior_signal = stats.norm(self.mu[1],self.sigma[1]).pdf(x)\n",
    "          marginal_noise = [p+conditional[i]*prior_noise \n",
    "                              for i,p in enumerate(marginal_noise)];\n",
    "          marginal_signal = [p+conditional[i]*prior_signal \n",
    "                               for i,p in enumerate(marginal_signal)];\n",
    "\n",
    "\n",
    "        self.signal_dist = marginal_signal;\n",
    "\n",
    "        self.noise_dist = marginal_noise;\n",
    "\n",
    "      \n",
    "    def runModel(self, num_trials, num_timepoints):\n",
    "        \n",
    "        self.num_trials = num_trials;\n",
    "        self.num_timepoints = num_timepoints;\n",
    "        \n",
    "        self.df['trial_id'] = range(num_trials);\n",
    "        \n",
    "        # first, decide which is the true direction in each trial (p=0.5)\n",
    "        self.df['bright_side'] = [1 if flip else 0 \n",
    "                                for flip in np.random.binomial(1,0.5,num_trials)] \n",
    "        \n",
    "        # first, decide which is the true direction in each trial (p=0.5)\n",
    "        self.df['signal'] = [1 if flip else 0 \n",
    "                                for flip in np.random.binomial(1,0.5,num_trials)] \n",
    "        \n",
    "        # duplicate each row num_timepoints times\n",
    "        self.df = self.df.loc[self.df.index.repeat(num_timepoints)].reset_index(drop=True)\n",
    "\n",
    "        self.df['timepoint'] = list(range(1,num_timepoints+1))*num_trials;\n",
    "        \n",
    "        # duplicate each row twice (for the two evidence channels)\n",
    "        self.df = self.df.loc[self.df.index.repeat(2)].reset_index(drop=True)\n",
    "        \n",
    "        self.df['side'] = [1,0] * num_trials*num_timepoints;\n",
    "        \n",
    "        self.getMotionEnergy()\n",
    "        \n",
    "        self.extractLLR()\n",
    "\n",
    "        # I didn't have a better word for this part, which includes processing\n",
    "        # the stimuli, making a decision and rating confidence. \n",
    "        self.behave()\n",
    "        \n",
    "        self.df['correct'] = self.df.apply(lambda row: \n",
    "                                           row.signal==row.decision, axis=1)\n",
    "        \n",
    "    def getMotionEnergy(self):\n",
    "        \n",
    "        # sample the motion energy for left and right as a function of the true direction\n",
    "        self.df['evidence'] = self.df.apply(lambda row: \n",
    "                      np.random.normal(self.mu[1],self.sigma[1]) \n",
    "                      if (row.side==row.bright_side) & (row.signal)==1\n",
    "                      else np.random.normal(self.mu[0],self.sigma[0]),\n",
    "                      axis=1)\n",
    "\n",
    "        # how it appears to subjects\n",
    "        # how it appears to subjects\n",
    "        self.df['percept'] = self.df.apply(lambda row: np.random.poisson(max(0,row.evidence*20)), \n",
    "                        axis=1);\n",
    "    \n",
    "    def extractLLR(self):\n",
    "        \n",
    "        self.df['likelihood_signal'] = self.df.apply(lambda row: self.signal_dist[int(row.percept)], axis=1);\n",
    "        self.df['likelihood_noise'] = self.df.apply(lambda row: self.noise_dist[int(row.percept)], axis=1)\n",
    "        \n",
    "        # extract the Log Likelihood Ratio (LLR) \n",
    "        #log(p(evidence|signal))-log(p(evidence|noise))\n",
    "        self.df['sample_LLR'] = self.df.apply(lambda row: np.log(self.signal_dist[int(row.percept)])-\n",
    "                                              np.log(self.noise_dist[int(row.percept)]), axis=1)\n",
    "        \n",
    "    def behave(self):\n",
    "        \n",
    "        exp_LLR = [];\n",
    "        exp_decision = [];\n",
    "        exp_confidence = [];\n",
    "\n",
    "        trials=self.df.trial_id.unique()\n",
    "\n",
    "        for i_trial in range(self.num_trials):\n",
    "            trial_df = self.df[self.df.trial_id==i_trial]\n",
    "            trial_LLR = [0,0];\n",
    "\n",
    "            LLR1 = 0; # likelihood ratio regarding the two side of the signal, conditioned on that there is a signal\n",
    "            LLR_present = 0;\n",
    "            \n",
    "            for i_timepoint in range(2,self.num_timepoints+1):\n",
    "\n",
    "                sample1 = trial_df[(trial_df.timepoint==i_timepoint) & \n",
    "                                   (trial_df.side==1)]['sample_LLR'].values[0];\n",
    "                sample0 = trial_df[(trial_df.timepoint==i_timepoint) & \n",
    "                                   (trial_df.side==0)]['sample_LLR'].values[0];\n",
    "                \n",
    "                psignal1 = trial_df[(trial_df.timepoint==i_timepoint) & \n",
    "                                   (trial_df.side==1)]['likelihood_signal'].values[0];\n",
    "                psignal0 = trial_df[(trial_df.timepoint==i_timepoint) & \n",
    "                                   (trial_df.side==0)]['likelihood_signal'].values[0];\n",
    "                \n",
    "                pnoise1 = trial_df[(trial_df.timepoint==i_timepoint) & \n",
    "                                   (trial_df.side==1)]['likelihood_noise'].values[0];\n",
    "                pnoise0 = trial_df[(trial_df.timepoint==i_timepoint) & \n",
    "                                   (trial_df.side==0)]['likelihood_noise'].values[0];\n",
    "                \n",
    "                p1 = LLR2p(LLR1); # the probability that side==1\n",
    "                \n",
    "                LLR_present = LLR_present + \\\n",
    "                np.log(p1*psignal1*pnoise0 + (1-p1)*pnoise1*psignal0) - \\\n",
    "                np.log(pnoise0*pnoise1)\n",
    "                \n",
    "                LLR1 = LLR1+sample1-sample0;\n",
    "\n",
    "                trial_LLR += [LLR_present,LLR_present]\n",
    "\n",
    "            trial_decision = [int(LLR_present>0)]*24\n",
    "            trial_confidence = [LLR2pcorrect(LLR_present)]*24     \n",
    "\n",
    "            exp_LLR = exp_LLR + trial_LLR;\n",
    "            exp_decision = exp_decision+trial_decision;\n",
    "            exp_confidence = exp_confidence+trial_confidence;\n",
    "\n",
    "        self.df['LLR'] = exp_LLR;\n",
    "        self.df['decision'] = exp_decision;\n",
    "        self.df['confidence'] = exp_confidence;\n",
    "        \n",
    "    def save(self,file_name):\n",
    "        self.df.to_csv(file_name);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "uv_det=DetectionModel([0,0.5],[1,1])\n",
    "uv_det.runModel(10000,12)\n",
    "uv_det.save(path.join(\n",
    "        '..','simulations','poisson_noise','detection.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5106"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uv_det.df.correct.mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
